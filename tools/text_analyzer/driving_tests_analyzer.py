#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∏–ª–µ—Ç–æ–≤ –ø–æ –≤–æ–∂–¥–µ–Ω–∏—é

–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ HTML —Å—Ç—Ä–∞–Ω–∏—Ü —Å –±–∏–ª–µ—Ç–∞–º–∏
–ø–æ –≤–æ–∂–¥–µ–Ω–∏—é –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è Excel –æ—Ç—á—ë—Ç–æ–≤ —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º
"""

import os
import sys
from pathlib import Path
from datetime import datetime
import glob
import logging
import pandas as pd
from collections import Counter

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from spanish_analyser import SpanishTextProcessor, WordAnalyzer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DrivingTestsAnalyzer:
    """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –±–∏–ª–µ—Ç–æ–≤ –ø–æ –≤–æ–∂–¥–µ–Ω–∏—é"""
    
    def __init__(self, 
                 downloads_path: str = "../data/downloads",
                 results_path: str = "../data/results",
                 max_files: int = 20):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            downloads_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ HTML —Ñ–∞–π–ª–∞–º–∏
            results_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
            max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.downloads_path = Path(downloads_path)
        self.results_path = Path(results_path)
        self.max_files = max_files
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.results_path.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.text_processor = SpanishTextProcessor()
        self.word_analyzer = WordAnalyzer()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_stats = {
            'files_processed': 0,
            'words_found': 0,
            'start_time': datetime.now()
        }
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"–ü–∞–ø–∫–∞ –∑–∞–≥—Ä—É–∑–æ–∫: {self.downloads_path}")
        logger.info(f"–ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {self.results_path}")
    
    def find_html_files(self, pattern: str = "*.html") -> list:
        """
        –ù–∞—Ö–æ–¥–∏—Ç HTML —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            pattern: –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ HTML —Ñ–∞–π–ª–∞–º
        """
        html_files = list(self.downloads_path.glob(pattern))
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(html_files)} HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return html_files
    
    def extract_text_from_html(self, html_file: Path) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ HTML —Ñ–∞–π–ª–∞
        
        Args:
            html_file: –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
            
        Returns:
            –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # –û—á–∏—â–∞–µ–º HTML —Ç–µ–≥–∏
            cleaned_text = self.text_processor.clean_text(html_content, remove_prefixes=False)
            
            logger.debug(f"–ò–∑–≤–ª–µ—á—ë–Ω —Ç–µ–∫—Å—Ç –∏–∑ {html_file.name}: {len(cleaned_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return cleaned_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ {html_file.name}: {e}")
            return ""
    
    def analyze_html_files(self, html_files: list = None) -> dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTML —Ñ–∞–π–ª—ã –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ª–æ–≤–∞
        
        Args:
            html_files: –°–ø–∏—Å–æ–∫ HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞
        """
        if html_files is None:
            html_files = self.find_html_files()
        
        logger.info(f"–ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ {len(html_files)} HTML —Ñ–∞–π–ª–æ–≤")
        
        total_words = 0
        
        for html_file in html_files:
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                text = self.extract_text_from_html(html_file)
                if text:
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
                    self.word_analyzer.add_words_from_text(text)
                    
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞ –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ
                    words_in_file = len(self.text_processor.extract_spanish_words(text))
                    total_words += words_in_file
                    
                    self.analysis_stats['files_processed'] += 1
                    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω {html_file.name}: –Ω–∞–π–¥–µ–Ω–æ {words_in_file} —Å–ª–æ–≤")
                else:
                    logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω {html_file.name}: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç")
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {html_file.name}: {e}")
        
        self.analysis_stats['words_found'] = total_words
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.analysis_stats['files_processed']}")
        logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {total_words}")
        
        return {
            'files_processed': self.analysis_stats['files_processed'],
            'words_found': total_words,
            'unique_words': len(self.word_analyzer.word_frequencies)
        }
    
    def generate_filename_with_timestamp(self, prefix: str = "word_analysis") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        
        Args:
            prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            
        Returns:
            –ò–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{prefix}_{timestamp}.xlsx"
    
    def cleanup_old_files(self):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è –Ω–µ –±–æ–ª–µ–µ max_files"""
        try:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ Excel —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            excel_files = list(self.results_path.glob("*.xlsx"))
            
            if len(excel_files) > self.max_files:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è (—Å—Ç–∞—Ä—ã–µ –ø–µ—Ä–≤—ã–º–∏)
                excel_files.sort(key=lambda x: x.stat().st_mtime)
                
                # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
                files_to_delete = excel_files[:-self.max_files]
                
                for old_file in files_to_delete:
                    old_file.unlink()
                    logger.info(f"–£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {old_file.name}")
                
                logger.info(f"–£–¥–∞–ª–µ–Ω–æ {len(files_to_delete)} —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
    
    def export_results(self, include_categories: bool = True) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ Excel
        
        Args:
            include_categories: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
            filename = self.generate_filename_with_timestamp("driving_tests_analysis")
            file_path = self.results_path / filename
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.word_analyzer.export_to_excel(str(file_path), include_categories)
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
            self.cleanup_old_files()
            
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤: {filename}")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            return ""
    
    def get_analysis_summary(self) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –∞–Ω–∞–ª–∏–∑—É"""
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç WordAnalyzer
        word_stats = self.word_analyzer.get_summary_stats()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—à—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        analysis_summary = {
            'files_processed': self.analysis_stats['files_processed'],
            'words_found': self.analysis_stats['words_found'],
            'unique_words': word_stats['–≤—Å–µ–≥–æ_—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö_—Å–ª–æ–≤'],
            'known_words': word_stats['–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö_—Å–ª–æ–≤'],
            'new_words': word_stats['–Ω–æ–≤—ã—Ö_—Å–ª–æ–≤'],
            'analysis_time': str(datetime.now() - self.analysis_stats['start_time'])
        }
        
        return analysis_summary
    
    def reset_analysis(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        self.word_analyzer.reset()
        self.analysis_stats = {
            'files_processed': 0,
            'words_found': 0,
            'start_time': datetime.now()
        }
        logger.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–±—Ä–æ—à–µ–Ω—ã")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üìä –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∏–ª–µ—Ç–æ–≤ –ø–æ –≤–æ–∂–¥–µ–Ω–∏—é\n")
    
    # –°–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = DrivingTestsAnalyzer(
        downloads_path="../../data/downloads",
        results_path="../../data/results"
    )
    
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º HTML —Ñ–∞–π–ª—ã
        print("–ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ HTML —Ñ–∞–π–ª–æ–≤...")
        analysis_result = analyzer.analyze_html_files()
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {analysis_result['files_processed']}")
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {analysis_result['words_found']}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {analysis_result['unique_words']}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüìÅ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
        export_file = analyzer.export_results()
        
        if export_file:
            print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤: {export_file}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–≤–æ–¥–∫—É
        summary = analyzer.get_analysis_summary()
        print(f"\nüìã –°–≤–æ–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {summary['analysis_time']}")
        print(f"   –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–ª–æ–≤: {summary['known_words']}")
        print(f"   –ù–æ–≤—ã—Ö —Å–ª–æ–≤: {summary['new_words']}")
        
    except Exception as e:
        print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
